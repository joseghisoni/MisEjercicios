{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# IMPORTS\n",
    "# Core PyTorch + numerical and imaging utilities for Gaussian Splatting demo.\n",
    "# ---------------------------------------------\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from MS_SSIM_L1_loss import MS_SSIM_L1_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# DEVICE SELECTION\n",
    "# Select GPU if available for faster splatting + optimization.\n",
    "# ---------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5b534",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "We load a reference target image from a remote URL and convert it to a normalized 100x100 grayscale tensor. This target acts as supervision for our Gaussian parameter optimization. Keeping dimensions small accelerates iterations and illustrates the principle without heavy compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# DATA LOADING FROM URL\n",
    "# Robustly resolve ibb.co page URLs to a direct image.\n",
    "# Tries common meta tags (og:image, twitter:image) and <img src> fallbacks.\n",
    "# ---------------------------------------------\n",
    "import re\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "image_url = 'https://ibb.co/wNd95BZn'  # Source page hosting the image\n",
    "\n",
    "def _first_match(html: str, patterns):\n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, html, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            # Return first non-empty captured group\n",
    "            for g in m.groups():\n",
    "                if g:\n",
    "                    return g\n",
    "    return None\n",
    "\n",
    "def fetch_image_from_url(url: str) -> Image.Image:\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    content_type = resp.headers.get('content-type', '').lower()\n",
    "    # Case 1: Direct image URL\n",
    "    if 'image' in content_type:\n",
    "        return Image.open(BytesIO(resp.content))\n",
    "    \n",
    "    # Case 2: HTML page (e.g., ibb.co) -> parse for a direct image\n",
    "    html = resp.text\n",
    "    candidates = []\n",
    "    # Prefer Open Graph image first\n",
    "    candidates.append(_first_match(html, [\n",
    "        r'<meta[^>]+property=[\"\\']og:image[\"\\'][^>]+content=[\"\\']([^\"\\']+)[\"\\']',\n",
    "        r'<meta[^>]+content=[\"\\']([^\"\\']+)[\"\\'][^>]+property=[\"\\']og:image[\"\\']',\n",
    "    ]))\n",
    "    # Try Twitter card image\n",
    "    candidates.append(_first_match(html, [\n",
    "        r'<meta[^>]+name=[\"\\']twitter:image[\"\\'][^>]+content=[\"\\']([^\"\\']+)[\"\\']',\n",
    "        r'<meta[^>]+content=[\"\\']([^\"\\']+)[\"\\'][^>]+name=[\"\\']twitter:image[\"\\']',\n",
    "    ]))\n",
    "    # Fallback: any <img> referencing i.ibb.co (the direct CDN)\n",
    "    candidates.append(_first_match(html, [\n",
    "        r'<img[^>]+src=[\"\\'](https?://i\\.ibb\\.co/[^\"\\']+)[\"\\']',\n",
    "        r'<img[^>]+data-src=[\"\\'](https?://i\\.ibb\\.co/[^\"\\']+)[\"\\']',\n",
    "    ]))\n",
    "    \n",
    "    direct_img_url = next((c for c in candidates if c), None)\n",
    "    if not direct_img_url:\n",
    "        raise RuntimeError('Could not resolve a direct image URL from the provided page.')\n",
    "    \n",
    "    img_resp = requests.get(direct_img_url, timeout=30)\n",
    "    img_resp.raise_for_status()\n",
    "    if 'image' not in img_resp.headers.get('content-type','').lower():\n",
    "        raise RuntimeError('Resolved URL did not return an image content-type.')\n",
    "    return Image.open(BytesIO(img_resp.content))\n",
    "\n",
    "# Load the image\n",
    "image = fetch_image_from_url(image_url)  # PIL Image\n",
    "\n",
    "# Transform to grayscale 100x100 tensor for optimization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),       # Convert RGB/RGBA -> 1 channel\n",
    "    transforms.Resize((100,100)), # Standard resolution for this demo\n",
    "    transforms.ToTensor(),        # -> [C,H,W] float in [0,1]\n",
    "])\n",
    "target_image = transform(image)  # Shape: [1,100,100]\n",
    "\n",
    "# Quick visualization of target\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(target_image.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101d85b",
   "metadata": {},
   "source": [
    "# Ejercicio 1: Motor de render con Gaussian Splatting\n",
    "En este práctico vas a implementar partes clave del motor de render 2D basado en la suma aditiva de gaussianas anisotrópicas.\n",
    "\n",
    "Cada gaussiana (\"splat\") tiene:\n",
    "- Centro `(x, y)` en espacio normalizado `[0,1]^2`.\n",
    "- Escalas `(sigma_x, sigma_y)` que controlan el spread principal.\n",
    "- Rotación `theta` (radianes) que orienta la anisotropía.\n",
    "- Alpha (peso de contribución u \"opacidad\" relativa).\n",
    "\n",
    "La matriz de covarianza combina escalas + rotación para definir el óvalo (elipse) de cada gaussiana. El render final surge de evaluar las PDFs multivariadas sobre una grilla de píxeles y acumularlas.\n",
    "\n",
    "Tu objetivo hoy:\n",
    "1. Completar `build_covariance_matrix` para obtener `cov_mat = R @ S @ S^T @ R^T`.\n",
    "2. Completar `create_gaussian_image`:\n",
    "   - Construir matrices de rotación.\n",
    "   - Crear grilla de coordenadas y vectorizar evaluación.\n",
    "   - Instanciar la distribución multivariada y acumular contribuciones.\n",
    "   - (Opcional) Normalizar a `[0,1]` al final.\n",
    "3. Completar el loop de entrenamiento con cálculo de pérdidas, backward y snapshots.\n",
    "\n",
    "Recomendaciones:\n",
    "- Evitá loops Python cuando puedas vectorizar (excepto el loop por gaussiana ya provisto si decidís mantenerlo para claridad).\n",
    "- Usá `torch.distributions.MultivariateNormal` correctamente (mean en coordenadas de píxel, covarianza 2x2).\n",
    "- Revisá que no haya gradientes bloqueados (tensores deben tener `requires_grad` donde corresponde).\n",
    "\n",
    "Cuando termines cada sección, probá render inicial antes de pasar al entrenamiento.\n",
    "¡Adelante!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# GAUSSIAN PRIMITIVE + RENDERING UTILITIES (EJERCICIO)\n",
    "# En esta versión, varias partes están como \"placeholders\" para completar.\n",
    "# Líneas clave quedan pre-completadas; seguí las instrucciones TODO.\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "def build_covariance_matrix(S, R):\n",
    "    \"\"\"\n",
    "    EJERCICIO: construir la matriz de covarianza 2x2 por gaussiana a partir de\n",
    "    escalas diagonales y rotación.\n",
    "\n",
    "    Pistas:\n",
    "    - Usá torch.diag_embed para pasar de [N,2] -> [N,2,2]\n",
    "    - Recordá que, si S es diagonal, S @ S^T = diag(sigma_x^2, sigma_y^2)\n",
    "    - Fórmula objetivo: cov = R @ S @ S^T @ R^T\n",
    "    - Devolvé un tensor [N,2,2]\n",
    "    \"\"\"\n",
    "   \n",
    "    raise NotImplementedError(\"Completar: calcular 'cov_mat' y retornarlo\")\n",
    "    # return cov_mat\n",
    "\n",
    "\n",
    "\n",
    "def create_gaussian_image(centers, scales, rotations, alphas, image_size):\n",
    "    \"\"\"\n",
    "    EJERCICIO: renderizar una imagen 2D como suma de gaussianas anisotrópicas.\n",
    "    Completá los pasos marcados con TODO. Retorna un tensor [1, H, W].\n",
    "    \"\"\"\n",
    "    # Pre-completado: inicializar imagen en el dispositivo seleccionado\n",
    "    # Inicialización con requires_grad=True para que el optimizador pueda backpropagar\n",
    "    image = torch.zeros(image_size, image_size, requires_grad=True, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Pre-completado: transforms para asegurar rangos válidos\n",
    "    adjusted_centers = centers               # Se asume en [0,1]\n",
    "    adjusted_scales  = F.softplus(scales)    # Softplus -> escalas positivas\n",
    "    adjusted_alphas  = F.sigmoid(alphas)     # Sigmoid -> pesos en [0,1]\n",
    "\n",
    "    # TODO: construir matrices de rotación 2x2 a partir del ángulo 'rotations' (en radianes)\n",
    "    \n",
    "\n",
    "    # Mantener esta línea: compone escala + rotación en la covarianza\n",
    "    cov_matrices = build_covariance_matrix(adjusted_scales, rotation_matrices).to(device)\n",
    "\n",
    "    # TODO: crear la grilla de coordenadas de píxeles y vectorizar\n",
    "    # Pistas:\n",
    "   \n",
    "    # Mantener: encabezado del loop para acumular contribuciones de cada gaussiana\n",
    "    for center, cov_mat, alpha in zip(adjusted_centers, cov_matrices, adjusted_alphas):\n",
    "        # TODO:\n",
    "        # 1) Definir MultivariateNormal con mean=(center * image_size) y covariance_matrix=cov_mat\n",
    "        # 2) Evaluar log_prob en 'coords' y convertir a probs con torch.exp(...)\n",
    "        # 3) Dar forma [H,W] y sumar a 'image' con: image = image + (alpha * probs)\n",
    "        raise NotImplementedError(\"Completar: evaluación de gaussianas y composición aditiva\")\n",
    "\n",
    "    # TODO normalizar la imagen a [0,1] para estabilizar la escala del loss\n",
    "    # image = image / image.max()\n",
    "\n",
    "    return image.unsqueeze(0)  # Shape: [1, H, W]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64dce31",
   "metadata": {},
   "source": [
    "# Optimizer loop\n",
    "We initialize N Gaussian primitives with random parameters. During training we minimize a hybrid loss:\n",
    "- L1 (pixel-wise) to encourage accurate intensity reconstruction.\n",
    "- MS-SSIM-based perceptual component for structural fidelity.\n",
    "Parameters optimized: centers, scales (through softplus), alphas (sigmoid), rotations (angle). Saving intermediate renders every 100 iterations illustrates convergence dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14111aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# PARAMETER INITIALIZATION\n",
    "# Randomly initialize Gaussian parameters. For teaching:\n",
    "# - centers in [0,1]^2 (multiplied by image_size inside render)\n",
    "# - scales (pre-softplus) roughly positive after transform\n",
    "# - alphas random then sigmoid -> blending weight\n",
    "# - rotations in [0,1] mapped directly to radians (could scale to 2π)\n",
    "# ---------------------------------------------\n",
    "gcount = 500            # Number of Gaussian splats\n",
    "image_size = 100        # Output resolution (H= W= image_size)\n",
    "\n",
    "isotropic_scales_init_x = torch.rand(gcount, requires_grad=True, device=device)\n",
    "isotropic_scales_init_y = isotropic_scales_init_x  # Start isotropic; will diverge through optimization\n",
    "\n",
    "# Wrap trainable tensors in Parameters (double for higher precision if desired)\n",
    "centers   = torch.nn.Parameter(torch.rand((gcount, 2), requires_grad=True, device=device).double())\n",
    "scales    = torch.nn.Parameter(10*torch.stack((isotropic_scales_init_x,isotropic_scales_init_y),dim=1).double())\n",
    "alphas    = torch.nn.Parameter(torch.randn(gcount, 1, requires_grad=True, device=device).double())\n",
    "rotations = torch.nn.Parameter(torch.rand(gcount, requires_grad=True, device=device).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# INITIAL RENDER (BEFORE OPTIMIZATION)\n",
    "# Useful baseline to visualize random splat configuration.\n",
    "# ---------------------------------------------\n",
    "gaussian_image = create_gaussian_image(centers, scales, rotations, alphas, image_size)\n",
    "gaussian_image_init = gaussian_image.clone()  # Preserve initial state for later comparison\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(gaussian_image.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# OPTIMIZER + LOSS SETUP\n",
    "# Adam optimizer over all Gaussian parameters.\n",
    "# Loss mixing: majority weight on L1, minority on MS-SSIM perceptual term.\n",
    "# ---------------------------------------------\n",
    "optimizer = optim.Adam([centers, scales, alphas, rotations], lr=0.01)\n",
    "num_iterations = 2500  # Feel free to reduce for classroom demos\n",
    "\n",
    "# L1 loss: pixel-wise absolute difference. Encourages exact intensity matching\n",
    "# and is robust to outliers compared to L2. Provides a strong local reconstruction signal.\n",
    "criterion_L1 = torch.nn.L1Loss()\n",
    "\n",
    "# MS_SSIM_L1_LOSS: custom module combining multi-scale structural similarity (MS-SSIM)\n",
    "# with a smoothed L1 component. MS-SSIM captures perceptual/structural fidelity\n",
    "# (edges, contrast relationships) across scales, complementing the purely local\n",
    "# pixel-wise L1 term. Its output is already a loss (lower is better).\n",
    "# Expects input tensors of shape [B, C, H, W] on the same device.\n",
    "# See: https://en.wikipedia.org/wiki/Structural_similarity_index_measure \n",
    "criterion_SSIM = MS_SSIM_L1_LOSS(device=device)  # [B,C,H,W]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1da173",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Loop de Entrenamiento\n",
    "\n",
    "Completar la celda del loop para optimizar los parámetros de las gaussianas. El objetivo es minimizar una pérdida híbrida que combine reconstrucción (L1) y percepción/estructura (MS-SSIM) sobre la imagen objetivo.\n",
    "\n",
    "### Pasos obligatorios\n",
    "1. Calcular `loss_l1`:\n",
    "   - Usar `criterion_L1(gaussian_image, target_image)` (ajustar `squeeze()` y `.to(device)` según corresponda).\n",
    "2. Calcular `loss_ssim`:\n",
    "   - Usar `criterion_SSIM` con tensores `[B, C, H, W]` (agregar batch dim con `unsqueeze(0)` si hace falta).\n",
    "3. Combinar pérdidas:\n",
    "   - Sugerido: `loss = 0.8 * loss_l1 + 0.2 * loss_ssim` (podés experimentar otros pesos y discutirlo luego).\n",
    "4. Backprop y actualización:\n",
    "   - `loss.backward()` seguido de `optimizer.step()`.\n",
    "5. Snapshots periódicos (cada 100 iteraciones, configurable):\n",
    "   - Crear carpeta `status/` si no existe.\n",
    "   - Guardar la imagen: `plt.imsave('status/iter_XXXX.png', ...)` usando tensor procesado (`detach()`, `clamp(0,1)`, `cpu()`).\n",
    "6. Logging:\n",
    "   - `print` de iteración, `loss` total y componentes (`loss_l1`, `loss_ssim`).\n",
    "7. Mientras falten implementaciones mantener el `raise NotImplementedError` para evitar correr entrenamiento incompleto.\n",
    "\n",
    "### Extensiones opcionales\n",
    "- Scheduler de LR (`torch.optim.lr_scheduler`).\n",
    "- Gradient clipping (`torch.nn.utils.clip_grad_norm_`).\n",
    "- Early stopping por estabilización de la pérdida.\n",
    "- Métrica extra: PSNR o MSE para comparación cuantitativa.\n",
    "- Guardar GIF de convergencia (ej. con `imageio`).\n",
    "\n",
    "### Checklist antes de entrenar\n",
    "- [ ] `build_covariance_matrix` completo.\n",
    "- [ ] `create_gaussian_image` completo.\n",
    "- [ ] Loop con pérdidas, backward, step, snapshots y logging.\n",
    "\n",
    "Cuando todo funcione: retirar el `raise NotImplementedError`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# TRAINING LOOP (EJERCICIO)\n",
    "# Varias partes fueron reemplazadas por TODOs para que las completes.\n",
    "# Se preservan llamadas clave y estructura general.\n",
    "# ---------------------------------------------\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()  # Resetear gradientes acumulados\n",
    "\n",
    "    # Render actual con los parámetros corrientes\n",
    "    gaussian_image = create_gaussian_image(centers, scales, rotations, alphas, image_size)\n",
    "\n",
    "    # TODO: calcular la pérdida L1 entre gaussian_image y target_image\n",
    "\n",
    "    # TODO: calcular la pérdida perceptual MS-SSIM usando criterion_SSIM\n",
    "\n",
    "    # TODO: combinar pérdidas en variable 'loss' (por ejemplo 0.8 * loss_l1 + 0.2 * loss_ssim)\n",
    "\n",
    "    # TODO: backward() para propagar gradientes y luego optimizer.step() para actualizar parámetros\n",
    "\n",
    "    # TODO: cada x iteraciones guardar snapshot en carpeta 'status' (crear si no existe)\n",
    "\n",
    "    # TODO: imprimir métricas de la iteración (loss total y componentes)\n",
    "\n",
    "    raise NotImplementedError(\"Completar loop de entrenamiento: cálculo de pérdidas, backward, snapshots y logging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b45fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# FINAL RENDER AFTER TRAINING\n",
    "# ---------------------------------------------\n",
    "gaussian_image = create_gaussian_image(centers, scales, rotations, alphas, image_size)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(gaussian_image.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ddf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target reference image (supervision)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(target_image.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4af446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial random configuration (baseline)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(gaussian_image_init.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4033bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# SAVE TRAINED PARAMETERS\n",
    "# Centers, scales (pre-softplus), alphas (pre-sigmoid), rotations.\n",
    "# Re-load later to resume or visualize.\n",
    "# ---------------------------------------------\n",
    "torch.save({\n",
    "    'centers': centers,\n",
    "    'scales': scales,\n",
    "    'alphas': alphas,\n",
    "    'rotations': rotations\n",
    "}, 'gaussians.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# RELOAD PARAMETERS\n",
    "# Useful for separate visualization pass or continued fine-tuning.\n",
    "# ---------------------------------------------\n",
    "checkpoint = torch.load('gaussians.pth')\n",
    "centers   = checkpoint['centers']\n",
    "scales    = checkpoint['scales']\n",
    "alphas    = checkpoint['alphas']\n",
    "rotations = checkpoint['rotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51617d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# OPTIONAL: RESCALED SPLATS\n",
    "# Example of post-processing: adjusting scales for sharper rendering.\n",
    "# ---------------------------------------------\n",
    "shrinked_scales = scales * 1.\n",
    "gaussian_image = create_gaussian_image(centers, shrinked_scales, rotations, alphas, image_size)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(gaussian_image.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f8258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
